{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results for local code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab as pl\n",
    "import math\n",
    "import os\n",
    "import scipy.stats as st\n",
    "import pickle\n",
    "import seaborn as sns              # v 0.11.0\n",
    "\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create variables to store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "recalculate_if_saved = True\n",
    "repetitions = 18\n",
    "number_of_updates = 150\n",
    "algorithm_list = ['corrective', 'standard', 'preventive']\n",
    "types_list = ['concurrent']\n",
    "delay_list = ['1', '10', '100']\n",
    "repetition_probability_list = ['10']\n",
    "negation_probability_list = ['0', '10', '30']\n",
    "# Remove: just For debug purposes\n",
    "first_time = True\n",
    "\n",
    "index_list = []\n",
    "for i in range(150, 3150, 150):\n",
    "    index_list.append(i)\n",
    "\n",
    "file_path = 'local/test/results_experiment_'\n",
    "columns_metrics = ['inconsistencies', 'messages_sent', 'latency_per_operation', 'overhead_data_structure', 'overhead_per_message', 'number_of_reconfigurations', 'total_reconfiguration_time']\n",
    "new_columns_metrics = ['inconsistencies', \n",
    "                       'messages_sent', \n",
    "                       'latency_per_operation', \n",
    "                       'overhead_data_structure', \n",
    "                       'overhead_per_message', \n",
    "                       'number_of_reconfigurations', \n",
    "                       'total_reconfiguration_time',\n",
    "                       'result_algorithm',\n",
    "                       'type',\n",
    "                       'negation_probability',\n",
    "                       'delay',\n",
    "                       'repetition_probability',\n",
    "                       'update']\n",
    "file_path_images = '/images/'\n",
    "current_directory = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_empty_data():\n",
    "    data = dict()\n",
    "    data_mean = dict()\n",
    "    data_var = dict()\n",
    "    string_name = 'data_frame'\n",
    "            \n",
    "    for alg in algorithm_list:\n",
    "        for ty in types_list:\n",
    "            for dela in delay_list:\n",
    "                for rep in repetition_probability_list:\n",
    "                    for neg in negation_probability_list:\n",
    "                        var_name = string_name +'_' + alg + '_' + ty +'_delay_' + str(dela) + '_repetition_' + str(rep) + '_negation_' + str(neg)\n",
    "                        data[var_name] = pd.DataFrame(columns=columns_metrics, index=index_list)    \n",
    "                        data_mean[var_name] = pd.DataFrame(columns=columns_metrics, index=index_list)    \n",
    "                        data_var[var_name] = pd.DataFrame(columns=columns_metrics, index=index_list)    \n",
    "    return data, data_mean, data_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_data, dataframe_mean_data, dataframe_var_data = create_empty_data()\n",
    "all_results = pd.DataFrame(columns=new_columns_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_result(mean_vector, std_vector, var_vector, data):\n",
    "    var_name = 'data_frame' + '_' + data['algorithm'] + '_' + data['alg_type'] + '_delay_' + data['delay'] + '_repetition_' + data['repetition'] + '_negation_' + data['negation']\n",
    "    var = dataframe_data[var_name] \n",
    "    var_mean = dataframe_mean_data[var_name] \n",
    "    var_var = dataframe_var_data[var_name] \n",
    "    var.loc[data['update']] = mean_vector\n",
    "    var_mean.loc[data['update']] = std_vector\n",
    "    var_var.loc[data['update']] = var_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_all_dataframes_as_pickle():\n",
    "    print('Saving....')\n",
    "    current_directory = os.getcwd()\n",
    "    path_results = '/saved_dataframes/'\n",
    "    string_name = 'data_frame'\n",
    "            \n",
    "    for alg in algorithm_list:\n",
    "        for ty in types_list:\n",
    "            for dela in delay_list:\n",
    "                for rep in repetition_probability_list:\n",
    "                    for neg in negation_probability_list:\n",
    "                            var_name = string_name +'_' + alg + '_' + ty +'_delay_' + str(dela) + '_repetition_' + str(rep) + '_negation_' + str(neg)\n",
    "                            var = dataframe_data[var_name] \n",
    "                            pickle.dump(var, open(current_directory + path_results + var_name +'.p' , \"wb\"))\n",
    "                            var_mean = dataframe_mean_data[var_name] \n",
    "                            pickle.dump(var_mean, open(current_directory + path_results + var_name +'.p' , \"wb\"))\n",
    "                            var_var = dataframe_var_data[var_name] \n",
    "                            pickle.dump(var_var, open(current_directory + path_results + var_name +'.p' , \"wb\"))\n",
    "                                                                                                                \n",
    "    pickle.dump(dataframe_data, open(current_directory + path_results + '/single_value/dataframe_data.p' , 'wb'))\n",
    "    pickle.dump(dataframe_data, open(current_directory + path_results + '/single_value/dataframe_mean_data.p' , 'wb'))\n",
    "    pickle.dump(dataframe_data, open(current_directory + path_results + '/single_value/dataframe_var_data.p' , 'wb'))\n",
    "    print('Saved!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_and_save_value(result, data):\n",
    "#     low, high = st.t.interval(alpha=0.95, df=len(result)-1, loc=np.mean(result), scale=st.sem(result)) \n",
    "    mean_vector = result.mean(axis=0)\n",
    "#     if one_time_print == False:\n",
    "#         print('FIN RESULTADO')                        \n",
    "#         print(mean_vector)\n",
    "#         print(str(low[2]) + ', ' + str(high[2]))\n",
    "#         one_time_print = True\n",
    "#                                 st.t.interval(alpha=0.95, df=len(data)-1, loc=np.mean(data), scale=st.sem(data)) \n",
    "#                                 For overhead in KB divide by 1000 \n",
    "#                                 mean_vector = mean_vector / (1000.0)                                \n",
    "#                                 For the average latency divide the total latency by the reconfigurations                              \n",
    "#                                 mean_vector = mean_vector / (number_of_updates * (repetition_index + 1))  \n",
    "    std_vector = result.std(axis=0)\n",
    "    var_vector = result.var(axis=0)                            \n",
    "    add_result(mean_vector, std_vector, var_vector, data)                                \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_values(all_results):    \n",
    "    new_number = number_of_updates\n",
    "    one_time_print = False\n",
    "    for repetition_index in range(0, repetitions):\n",
    "        file_path = 'local/test/results_experiment_' + str(new_number)\n",
    "        data = dict()\n",
    "        data['update'] = number_of_updates * (repetition_index + 1)\n",
    "        for delay in delay_list:\n",
    "            data['delay'] = delay\n",
    "            for repetition_probability in repetition_probability_list:\n",
    "                data['repetition'] = repetition_probability\n",
    "                for negation_probability in negation_probability_list:\n",
    "                    data['negation'] = negation_probability\n",
    "                    for algorithm in algorithm_list:\n",
    "                        data['algorithm'] = algorithm\n",
    "                        for alg_type in types_list:  \n",
    "                            data['alg_type'] = alg_type\n",
    "                            str_1 = 'result_algorithm_*' + algorithm + '*_type_*' + alg_type + '*_negationProbability_*' + str(negation_probability)\n",
    "                            str_2 = '*_delay_*' + str(delay) + '.0*_repetitionProbability_*' + str(repetition_probability) + '*.csv'\n",
    "                            file_name = str_1 + str_2\n",
    "                            try:\n",
    "                                result = pd.read_csv(file_path +'/' + file_name, encoding='utf-8', sep=r'\\s*,\\s*', header=0, engine='python')                                \n",
    "                                result['result_algorithm'] = [algorithm]*len(result)\n",
    "                                result['type'] = [alg_type]*len(result)\n",
    "                                result['negation_probability'] = [str(negation_probability)]*len(result)\n",
    "                                result['delay'] = [str(delay)]*len(result)\n",
    "                                result['repetition_probability'] = [str(repetition_probability)]*len(result)\n",
    "                                result['update'] = [str( data['update'])]*len(result)\n",
    "                                \n",
    "                                for index, row in result.iterrows():                                           \n",
    "                                    all_results = all_results.append(row, ignore_index=False)                                      \n",
    "#                                 compute_and_save_value(result, data)\n",
    "                            except FileNotFoundError as e:\n",
    "                                print(e)\n",
    "\n",
    "        new_number += number_of_updates\n",
    "    save_all_dataframes_as_pickle()\n",
    "    return all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_values():\n",
    "    print('Loading...')\n",
    "    path_results = '/saved_dataframes/'\n",
    "    current_directory = os.getcwd()\n",
    "    loaded_data = pickle.load(open(current_directory + path_results + '/single_value/dataframe_data.p' , 'rb'))\n",
    "    loaded_mean_data = pickle.load(open(current_directory + path_results + '/single_value/dataframe_data.p' , 'rb'))\n",
    "    loaded_var_data = pickle.load(open(current_directory + path_results + '/single_value/dataframe_data.p' , 'rb'))\n",
    "    print('Loaded!')\n",
    "    return loaded_data, loaded_mean_data, loaded_var_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving....\n",
      "Saved!\n"
     ]
    }
   ],
   "source": [
    "if recalculate_if_saved:\n",
    "    all_results = calculate_values(all_results)\n",
    "else:\n",
    "    dataframe_data, dataframe_mean_data, dataframe_var_data = load_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the results with the correct names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_data_frame_with_correct_names(my_results, my_index, type_exp, my_metric):\n",
    "    my_indexes = 0\n",
    "    my_string_corrective = 'data_frame_corrective_' + type_exp\n",
    "    my_string_preventive = 'data_frame_preventive_' + type_exp\n",
    "    my_string_standard = 'data_frame_standard_' + type_exp\n",
    "    \n",
    "    for dela in delay_list:\n",
    "        str_del = '_delay_' + str(dela)\n",
    "        my_dict = dict()\n",
    "        my_dict['x_values'] = my_index\n",
    "        for neg in negation_probability_list:\n",
    "                str_neg = '_negation_' + str(neg)\n",
    "                if neg == '70':\n",
    "                    negation_index_list.append(my_indexes)\n",
    "                for rep in repetition_probability_list:\n",
    "                    str_rep = '_repetition_' + str(rep)\n",
    "                    corrective_string = my_string_corrective + str_del + str_rep + str_neg\n",
    "                    preventive_string = my_string_preventive + str_del +  str_rep + str_neg\n",
    "                    standard_string = my_string_standard + str_del + str_rep + str_neg            \n",
    "                    my_dict['y_corrective_' + str(rep)] = dataframe_data[corrective_string][my_metric]\n",
    "                    my_dict['y_corrective_mean_' + str(rep)] = dataframe_mean_data[corrective_string][my_metric]\n",
    "                    my_dict['y_preventive_' + str(rep)] = dataframe_data[preventive_string][my_metric]\n",
    "                    my_dict['y_preventive_mean_' + str(rep)] = dataframe_mean_data[preventive_string][my_metric]\n",
    "\n",
    "                    my_dict['y_standard_' + str(rep)] = dataframe_data[standard_string][my_metric]       \n",
    "                    my_dict['y_standard_mean_' + str(rep)] = dataframe_mean_data[standard_string][my_metric]   \n",
    "                my_results.append(pd.DataFrame(my_dict))\n",
    "                my_indexes += 1\n",
    "            \n",
    "    return my_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot inconsistencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_inconsistencies(metric, my_results, y_label, type_exp):\n",
    "    line_labels = ['Corrective 10% rep', 'Preventive 10% rep', 'Standard 10% rep']   \n",
    "    my_index = 0  # Possible numbers 0-9  \n",
    "    negation_70_index = 3\n",
    "    i = 2\n",
    "    j = 2\n",
    "    \n",
    "    fig, axs = plt.subplots(2, 3, figsize=(20,20)) \n",
    "    for i in range(0, 2):\n",
    "        for j in range(0, 3):    \n",
    "            axs[i, j].plot('x_values', 'y_corrective_10', data=my_results[my_index], marker='^', color='green', linewidth=3, label='corrective 10', linestyle='-')                                    \n",
    "            axs[i, j].plot('x_values', 'y_preventive_10', data=my_results[my_index], marker='o', color='blue', linewidth=2, label='preventive 10')                        \n",
    "            axs[i, j].plot('x_values', 'y_standard_10', data=my_results[my_index], marker='s', color='red', linewidth=2, label='standard 10', linestyle='-')            \n",
    "            axs[i, j].set_title('Delay ' + str(delay_list[j]) + 'ms')\n",
    "            axs[i, j].legend(loc=\"upper left\", borderaxespad=0.2,title='Negation ' + negation_probability_list[i] + '%', labels=line_labels )\n",
    "            my_index += 1\n",
    "        negation_70_index +=4\n",
    "        \n",
    "        for ax in axs.flat:\n",
    "            ax.set(xlabel='Reconfigurations', ylabel=y_label)\n",
    "        \n",
    "        string_name_png = current_directory + file_path_images + '/png/'+metric +'/' + 'result_ ' + metric + '_' + type_exp + '.png'\n",
    "        plt.savefig(string_name_png, format='png', facecolor='white', edgecolor='none', dpi=600.0)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot other metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_other_metrics(metric, my_results, y_label, type_exp):\n",
    "#     print(type(my_results))\n",
    "#     print(my_results)\n",
    "#     display(my_results.head(10))\n",
    "    \n",
    "    if metric == 'overhead_data_structure':\n",
    "        line_labels = ['Corrective CF-C','Preventive CF-P', 'Standard NCF-E']\n",
    "        plt.plot('x_values', 'y_corrective_10', data=my_results[6], marker='^', color='green', linewidth=2, label='corrective 10', linestyle='-')    \n",
    "    else:\n",
    "        line_labels = ['Corrective CF-C 1ms', 'Corrective CF-C 10ms', 'Corrective CF-C 100ms','Preventive CF-P 1ms', 'Standard NCF-E 1ms']\n",
    "        plt.plot('x_values', 'y_corrective_10', data=my_results[6], marker='^', color='green', linewidth=2, label='corrective 10', linestyle='-')\n",
    "        plt.plot('x_values', 'y_corrective_10', data=my_results[7], marker='>', color='green', linewidth=2, label='corrective 10', linestyle='-')\n",
    "        plt.plot('x_values', 'y_corrective_10', data=my_results[8], marker='D', color='green', linewidth=2, label='corrective 10', linestyle='-')\n",
    "        plt.plot('x_values', 'y_preventive_10', data=my_results[8], marker='o', color='blue', linewidth=2, label='preventive 10')                        \n",
    "    plt.plot('x_values', 'y_standard_10', data=my_results[8], marker='s', color='red', linewidth=2, label='standard 10', linestyle='-')            \n",
    "    plt.title('Negation 30% Repetition 10%')\n",
    "    plt.legend(loc=\"upper left\", borderaxespad=0.2, labels=line_labels)    \n",
    "    plt.xlabel('Reconfigurations')\n",
    "    plt.ylabel(y_label)\n",
    "    \n",
    "    string_name_png = current_directory + file_path_images + '/png/'+metric +'/' + 'result_ ' + metric + '_' + type_exp + '.png'\n",
    "    plt.savefig(string_name_png, format='png', facecolor='white', edgecolor='none', dpi=600.0, bbox_inches='tight', pad_inches=0)\n",
    "    string_name_png = current_directory + file_path_images + '/eps/'+metric +'/' + 'result_ ' + metric + '_' + type_exp + '.eps'\n",
    "    plt.savefig(string_name_png, format='eps', facecolor='white', edgecolor='none', dpi=600.0, bbox_inches='tight', pad_inches=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot result first extra repetitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metric(metric='number_of_reconfigurations', type_exp='concurrent', y_label='Inconsistencies'):\n",
    "    my_index = dataframe_data['data_frame_corrective_concurrent_delay_100_repetition_10_negation_10'].index\n",
    "    my_results = []\n",
    "    my_metric = metric\n",
    "    negation_index_list = []\n",
    "    my_indexes = 0    \n",
    "    my_results = populate_data_frame_with_correct_names(my_results, my_index, type_exp, metric)\n",
    "    if metric == 'inconsistencies':        \n",
    "        plot_inconsistencies(metric, my_results, y_label, type_exp)\n",
    "    else:\n",
    "        plot_other_metrics(metric, my_results, y_label, type_exp)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot all metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# columns_metrics = ['inconsistencies', 'messages_sent', 'latency_per_operation', 'overhead_data_structure', 'number_of_reconfigurations']\n",
    "# ylabels = ['Inconsistencies', 'Messages sent', 'Latency per operation (s)', 'Overhead of data structure (Kb)', 'Extra reconfigurations']\n",
    "# types_list = ['concurrent']\n",
    "# y_label_index = 0\n",
    "# for col in columns_metrics:\n",
    "#     for ty in types_list:\n",
    "#         if col == 'latency_per_operation':\n",
    "#             plot_metric(col, ty, ylabels[y_label_index])  \n",
    "#         y_label_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>timepoint</th>\n",
       "      <th>event</th>\n",
       "      <th>region</th>\n",
       "      <th>signal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s13</td>\n",
       "      <td>18</td>\n",
       "      <td>stim</td>\n",
       "      <td>parietal</td>\n",
       "      <td>-0.017552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s5</td>\n",
       "      <td>14</td>\n",
       "      <td>stim</td>\n",
       "      <td>parietal</td>\n",
       "      <td>-0.080883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s12</td>\n",
       "      <td>18</td>\n",
       "      <td>stim</td>\n",
       "      <td>parietal</td>\n",
       "      <td>-0.081033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subject  timepoint event    region    signal\n",
       "0     s13         18  stim  parietal -0.017552\n",
       "1      s5         14  stim  parietal -0.080883\n",
       "2     s12         18  stim  parietal -0.081033"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inconsistencies</th>\n",
       "      <th>messages_sent</th>\n",
       "      <th>latency_per_operation</th>\n",
       "      <th>overhead_data_structure</th>\n",
       "      <th>overhead_per_message</th>\n",
       "      <th>number_of_reconfigurations</th>\n",
       "      <th>total_reconfiguration_time</th>\n",
       "      <th>result_algorithm</th>\n",
       "      <th>type</th>\n",
       "      <th>negation_probability</th>\n",
       "      <th>delay</th>\n",
       "      <th>repetition_probability</th>\n",
       "      <th>update</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>296</td>\n",
       "      <td>0.017</td>\n",
       "      <td>82760.0</td>\n",
       "      <td>251400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019</td>\n",
       "      <td>corrective</td>\n",
       "      <td>concurrent</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>359</td>\n",
       "      <td>0.040</td>\n",
       "      <td>178248.0</td>\n",
       "      <td>307895.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>corrective</td>\n",
       "      <td>concurrent</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>334</td>\n",
       "      <td>0.046</td>\n",
       "      <td>250664.0</td>\n",
       "      <td>284110.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>corrective</td>\n",
       "      <td>concurrent</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>95</td>\n",
       "      <td>296</td>\n",
       "      <td>0.091</td>\n",
       "      <td>12052.0</td>\n",
       "      <td>348096.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.048</td>\n",
       "      <td>standard</td>\n",
       "      <td>concurrent</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>74</td>\n",
       "      <td>359</td>\n",
       "      <td>0.121</td>\n",
       "      <td>26240.0</td>\n",
       "      <td>422184.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.059</td>\n",
       "      <td>standard</td>\n",
       "      <td>concurrent</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>157</td>\n",
       "      <td>676</td>\n",
       "      <td>0.199</td>\n",
       "      <td>38160.0</td>\n",
       "      <td>794976.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.095</td>\n",
       "      <td>standard</td>\n",
       "      <td>concurrent</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2216</td>\n",
       "      <td>143.190</td>\n",
       "      <td>8160.0</td>\n",
       "      <td>3412845.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.060</td>\n",
       "      <td>preventive</td>\n",
       "      <td>concurrent</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2600</td>\n",
       "      <td>192.263</td>\n",
       "      <td>8576.0</td>\n",
       "      <td>4017426.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.091</td>\n",
       "      <td>preventive</td>\n",
       "      <td>concurrent</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2496</td>\n",
       "      <td>179.288</td>\n",
       "      <td>8608.0</td>\n",
       "      <td>3844442.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.072</td>\n",
       "      <td>preventive</td>\n",
       "      <td>concurrent</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1036</td>\n",
       "      <td>0.092</td>\n",
       "      <td>92608.0</td>\n",
       "      <td>898355.0</td>\n",
       "      <td>388.0</td>\n",
       "      <td>0.030</td>\n",
       "      <td>corrective</td>\n",
       "      <td>concurrent</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   inconsistencies messages_sent  latency_per_operation  \\\n",
       "0                0           296                  0.017   \n",
       "1                0           359                  0.040   \n",
       "2                0           334                  0.046   \n",
       "0               95           296                  0.091   \n",
       "1               74           359                  0.121   \n",
       "..             ...           ...                    ...   \n",
       "2              157           676                  0.199   \n",
       "0                0          2216                143.190   \n",
       "1                0          2600                192.263   \n",
       "2                0          2496                179.288   \n",
       "0                0          1036                  0.092   \n",
       "\n",
       "    overhead_data_structure  overhead_per_message  number_of_reconfigurations  \\\n",
       "0                   82760.0              251400.0                         0.0   \n",
       "1                  178248.0              307895.0                         0.0   \n",
       "2                  250664.0              284110.0                         0.0   \n",
       "0                   12052.0              348096.0                        40.0   \n",
       "1                   26240.0              422184.0                        57.0   \n",
       "..                      ...                   ...                         ...   \n",
       "2                   38160.0              794976.0                        92.0   \n",
       "0                    8160.0             3412845.0                         0.0   \n",
       "1                    8576.0             4017426.0                         0.0   \n",
       "2                    8608.0             3844442.0                         0.0   \n",
       "0                   92608.0              898355.0                       388.0   \n",
       "\n",
       "    total_reconfiguration_time result_algorithm        type  \\\n",
       "0                        0.019       corrective  concurrent   \n",
       "1                        0.010       corrective  concurrent   \n",
       "2                        0.010       corrective  concurrent   \n",
       "0                        0.048         standard  concurrent   \n",
       "1                        0.059         standard  concurrent   \n",
       "..                         ...              ...         ...   \n",
       "2                        0.095         standard  concurrent   \n",
       "0                        0.060       preventive  concurrent   \n",
       "1                        0.091       preventive  concurrent   \n",
       "2                        0.072       preventive  concurrent   \n",
       "0                        0.030       corrective  concurrent   \n",
       "\n",
       "   negation_probability delay repetition_probability update  \n",
       "0                     0     1                     10    150  \n",
       "1                     0     1                     10    150  \n",
       "2                     0     1                     10    150  \n",
       "0                     0     1                     10    150  \n",
       "1                     0     1                     10    150  \n",
       "..                  ...   ...                    ...    ...  \n",
       "2                    10     1                     10    300  \n",
       "0                    10     1                     10    300  \n",
       "1                    10     1                     10    300  \n",
       "2                    10     1                     10    300  \n",
       "0                    30     1                     10    300  \n",
       "\n",
       "[100 rows x 13 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1458\n"
     ]
    }
   ],
   "source": [
    "# # Import dataset as a pandas dataframe\n",
    "df = sns.load_dataset('fmri')\n",
    "\n",
    "# print(df)\n",
    "\n",
    "display(df.head(3))\n",
    "\n",
    "# # Draw seaborn lineplot with error band based on the standard deviation\n",
    "# fig, ax = plt.subplots(figsize=(9,5))\n",
    "# sns.lineplot(data=df, x=\"timepoint\", y=\"signal\", ci='sd')\n",
    "# sns.despine()\n",
    "# plt.show()\n",
    "\n",
    "# print(all_results)\n",
    "\n",
    "display(all_results.head(100))\n",
    "print(len(all_results))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9,5))\n",
    "sns.lineplot(data=all_results, x=\"update\", y=\"latency_per_operation\", ci='sd')\n",
    "sns.despine()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
